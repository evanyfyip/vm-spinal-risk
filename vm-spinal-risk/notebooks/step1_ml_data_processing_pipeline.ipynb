{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e37ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/evan/Documents/School/MSDS/msds-capstone/vm-spinal-risk/vm-spinal-risk/notebooks'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import re\n",
    "# pipelining\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# constants\n",
    "data_fname = \"../data/all_risk_processed.csv\"\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b179cf",
   "metadata": {},
   "source": [
    "Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab101675-368d-4ddf-8012-76974e735caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 87)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(os.getcwd(), data_fname), index_col=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7689902e-3d6e-4d19-bdac-2bb04876ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropUnbalancedFeatures(BaseEstimator, TransformerMixin):\n",
    "  \"\"\"\n",
    "  Custom scikit-learn transformer to remove features with unbalanced distribution.\n",
    "  Author: Evan Yip\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  threshold : float, optional\n",
    "      The threshold for feature unbalance. Features with a dominant class percentage\n",
    "      exceeding this threshold will be dropped. Default is 0.9.\n",
    "  verbose : bool, optional\n",
    "      If True, print information about the features being removed during fit and\n",
    "      transformation. Default is True.\n",
    "\n",
    "  Attributes\n",
    "  ----------\n",
    "  threshold : float\n",
    "      The specified threshold for feature unbalance.\n",
    "  verbose : bool\n",
    "      Flag indicating whether to print information during fit and transform.\n",
    "  columns : list or None\n",
    "      List of feature names if input data is a DataFrame, otherwise None.\n",
    "  features_kept : list\n",
    "      Indices of features kept after applying the unbalance threshold.\n",
    "  features_dropped : list\n",
    "      Indices of features dropped after applying the unbalance threshold.\n",
    "\n",
    "  Methods\n",
    "  -------\n",
    "  fit(X, y=None)\n",
    "      Fit the transformer to the input data, identifying unbalanced features.\n",
    "  transform(X)\n",
    "      Transform the input data by keeping only the balanced features.\n",
    "  get_feature_names_out(input_features=None)\n",
    "      Return the names of the output features.\n",
    "\n",
    "  Notes\n",
    "  -----\n",
    "  - The transformer identifies features with a dominant class percentage exceeding\n",
    "    the specified threshold and drops them.\n",
    "  - The fit method prints information about the removed features if verbose is True.\n",
    "\n",
    "  Examples\n",
    "  --------\n",
    "  >>> transformer = DropUnbalancedFeatures(threshold=0.85, verbose=True)\n",
    "  >>> X_balanced = transformer.fit_transform(X_unbalanced)\n",
    "  \"\"\"\n",
    "  def __init__(self, threshold=0.9, verbose=True):\n",
    "    self.threshold = threshold\n",
    "    self.verbose = verbose\n",
    "    self.columns = None\n",
    "    self.features_kept = []\n",
    "    self.features_dropped = []\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    if self.verbose:\n",
    "      print(f\"Removing unbalanced features with (threshold={self.threshold})\")\n",
    "    X = X.copy()\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "      self.columns = list(X.columns)\n",
    "    else:\n",
    "      self.columns = None\n",
    "    self.features_dropped = []\n",
    "    for col_idx in range(X.shape[1]):\n",
    "      counts = np.unique(X.iloc[:, col_idx] if isinstance(X, pd.DataFrame) else X[:, col_idx], return_counts=True)[1]\n",
    "      percent = counts / counts.sum()\n",
    "\n",
    "      if (percent > self.threshold).any():\n",
    "          self.features_dropped.append(col_idx)\n",
    "      else:\n",
    "          self.features_kept.append(col_idx)\n",
    "    if self.verbose:\n",
    "      print(\"Parsing complete\")\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    if self.verbose:\n",
    "      if len(self.features_dropped) > 0:\n",
    "        print(f\"Removed: {self.features_dropped}\")\n",
    "      else:\n",
    "        print(\"No features removed\")\n",
    "    return X.iloc[:, self.features_kept] if isinstance(X, pd.DataFrame) else X[:, self.features_kept]\n",
    "\n",
    "  def get_feature_names_out(self, input_features=None):\n",
    "    if self.columns is not None:\n",
    "      output_features = [self.columns[i] for i in self.features_kept]\n",
    "      return output_features\n",
    "    else:\n",
    "      output_features = [input_features[i] for i in self.features_kept]\n",
    "      return output_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7afcae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['record_id', 'risk_1_timestamp', 'age', 'sex', 'height', 'weight',\n",
       "       'zipcode', 'ethnicity', 'income', 'education', 'prior_surg',\n",
       "       'spin_surg', 'succ_surg', 'religion', 'odi_1', 'odi_2', 'odi_3',\n",
       "       'odi_4', 'odi_5', 'odi_6', 'odi_7', 'odi_8', 'odi_9', 'odi_10',\n",
       "       'exer_50improv_1drop', 'exer_50improv_10drop', 'exer_50improv_50drop',\n",
       "       'exer_50improv_90drop', 'att_check_1', 'exer_90improv_1drop',\n",
       "       'exer_90improv_10drop', 'exer_90improv_50drop', 'exer_90improv_90drop',\n",
       "       'exer_50pain_1death', 'exer_50pain_10death', 'exer_50pain_50death',\n",
       "       'exer_90pain_1death', 'exer_90pain_10death', 'exer_90pain_50death',\n",
       "       'work_50improv_1drop', 'work_50improv_10drop', 'work_50improv_50drop',\n",
       "       'work_50improv_90drop', 'work_90improv_1drop', 'work_90improv_10drop',\n",
       "       'work_90improv_50drop', 'work_50improv_1para', 'work_50improv_10para',\n",
       "       'work_50improv_50para', 'work_50improv_90para', 'work_90improv_1para',\n",
       "       'work_90improv_10para', 'att_check2', 'work_90improv_50para',\n",
       "       'work_50improv_1death', 'work_50improv_10death',\n",
       "       'work_50improv_50death', 'work_90improv_1death',\n",
       "       'work_90improv_10death', 'work_90improv_50death', 'att_pass',\n",
       "       'odi_final', 'bmi', 'risk_1_complete', 'dospert_ethical',\n",
       "       'dospert_financial', 'dospert_health/safety', 'dospert_recreational',\n",
       "       'dospert_social', 'height_m', 'weight_kg', 'age_range', 'postal_code',\n",
       "       'city', 'state', 'state_code', 'province', 'province_code', 'latitude',\n",
       "       'longitude', 'fips', 'GISJOIN', 'FIPS', 'ADI_NATRANK', 'ADI_STATERNK',\n",
       "       'spinal_risk_score', 'old_spinal_risk_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38510443-2979-449a-8bfd-516089dbffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = data.drop(['odi_1', 'odi_2', 'odi_3',\n",
    "       'odi_4', 'odi_5', 'odi_6', 'odi_7', 'odi_8', 'odi_9', 'odi_10',\n",
    "       'exer_50improv_1drop', 'exer_50improv_10drop', 'exer_50improv_50drop',\n",
    "       'exer_50improv_90drop', 'att_check_1', 'exer_90improv_1drop',\n",
    "       'exer_90improv_10drop', 'exer_90improv_50drop', 'exer_90improv_90drop',\n",
    "       'exer_50pain_1death', 'exer_50pain_10death', 'exer_50pain_50death',\n",
    "       'exer_90pain_1death', 'exer_90pain_10death', 'exer_90pain_50death',\n",
    "       'work_50improv_1drop', 'work_50improv_10drop', 'work_50improv_50drop',\n",
    "       'work_50improv_90drop', 'work_90improv_1drop', 'work_90improv_10drop',\n",
    "       'work_90improv_50drop', 'work_50improv_1para', 'work_50improv_10para',\n",
    "       'work_50improv_50para', 'work_50improv_90para', 'work_90improv_1para',\n",
    "       'work_90improv_10para', 'att_check2', 'work_90improv_50para',\n",
    "       'work_50improv_1death', 'work_50improv_10death',\n",
    "       'work_50improv_50death', 'work_90improv_1death',\n",
    "       'work_90improv_10death', 'work_90improv_50death', 'att_pass',\n",
    "       'risk_1_complete','height', 'weight','record_id', 'risk_1_timestamp', \n",
    "       'zipcode','age_range', 'postal_code','state_code','city',\n",
    "       'province', 'province_code','latitude', 'longitude', 'FIPS', 'fips', 'GISJOIN', 'state'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69f99f18-0176-485d-a9b7-85c3213195e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "data_final['ADI_NATRANK'] = pd.to_numeric(data_final['ADI_NATRANK'], errors='coerce').astype(float).astype('Int64')\n",
    "data_final['ADI_STATERNK'] = pd.to_numeric(data_final['ADI_STATERNK'], errors='coerce').astype(float).astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56f397b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [\"religion\", \"ethnicity\"]\n",
    "cat_cols = [\"sex\", \"income\", \"education\", \"prior_surg\", \"spin_surg\", \"succ_surg\"]\n",
    "num_cols = [\"age\", \"odi_final\", \"bmi\", \"dospert_ethical\", \"dospert_financial\", \"dospert_health/safety\", \"dospert_recreational\", \"dospert_social\", \"height_m\", \"weight_kg\", \"ADI_NATRANK\", \"ADI_STATERNK\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df03623b-dd54-4806-9a9a-79dd49443225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing pipeline\n",
    "ohe_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')),\n",
    "    ('selector', DropUnbalancedFeatures(threshold=0.8, verbose=False))\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('selector', DropUnbalancedFeatures(threshold=0.8, verbose=False))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', IterativeImputer(random_state=52)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ohe', ohe_pipe, ohe_cols),\n",
    "        ('cat', cat_pipe, cat_cols),\n",
    "        ('num', num_pipe, num_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108887d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bbe1ced-b65d-4e87-b4a5-499ee599c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.fit(data_final)  # Fit the ColumnTransformer to your data\n",
    "transformed_columns = preprocessor.get_feature_names_out(input_features=data_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f544c07-f2d8-4e07-b516-637802e4b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_final = preprocessor.fit_transform(data_final)\n",
    "processed_final_df = pd.DataFrame(processed_final, columns=transformed_columns)\n",
    "processed_final_df['spinal_risk_score'] = data_final['spinal_risk_score']\n",
    "processed_final_df.to_csv('../data/ml_data_processed_final.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
